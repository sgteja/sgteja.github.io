- title: Structure from Motion (SFM)
  demo: http://sgteja.github.io/reports/SFM_classical.pdf
  # code: https://github.com/crowddj/crowddj-react
  description: SFM is about reconstructing a whole 3D scene and simultaneously obtaining camera poses from a set of images taken by a monocular camera at different locations and positions of a scene. The problem here is often referred to as Structure from Motion (SFM).
  img: SFM_classical
  used:
    - thing: Python
    - thing: OpenCV
    - thing: RANSAC
    - thing: Fundamental and Essential Matrix
    - thing: Nonlinear Triangulation
    - thing: Perspective-n-Point
    - thing: Bundle adjustment

- title: Learning SfM, an Unsupervised way
  demo:  http://sgteja.github.io/reports/SFM_deep.pdf
  description: An unsupervised learning approach for predicting the monocular depth and ego-motion from the video sequences. I improved the end-to-end learning approach presented in <a href="https://ai.google/research/pubs/pub46023/" target="_blank">SfMLearner</a>. In contrast to the original SfMLearner, our training data was limited to a subset of the original KITTI dataset. I used ResNet architecture for depth estimation, with SSIM and forward-backward consistency loss, which is from <a href="https://arxiv.org/abs/1803.02276" target="_blank">GeoNet</a>. The evaluations and comparison showed the effectiveness of my approach, which improved the abs_rel depth metric of SfMLearner by 18%.
  img: SFM_deep
  used:
    - thing: Python
    - thing: Tensor-Flow
    - thing: OpenCV
    - thing: SFMLearner
    - thing: KITTI dataset
    - thing: ResNet arhitecture
    - thing: Unsupervised Learning

- title: Face Swap
  demo: http://sgteja.github.io/reports/FaceSwap.pdf
  description: An end-to-end pipeline of swapping two faces in a video, by using both classical (Dlib library) and deep-learning (<a href="https://arxiv.org/abs/1803.07835" target="_blank">PRNet</a>) methods for getting facial fiducials. The Face Swap in two scenarios is shown, first between two faces in the same video and in second, a face in a video with a face in from given image. The resulting videos can be viewed <a href="https://drive.google.com/drive/folders/1TWO6Hed_34k3yZWGM-GOuf4xCKWST9Er?usp=sharing" target="_blank">here</a>.
  img: FaceSwap
  video: https://www.youtube.com/embed/hyz17mHsGcM?
  used:
    - thing: Python
    - thing: Tensor-Flow
    - thing: Dlib library
    - thing: OpenCV
    - thing: Delaunay Triangulation
    - thing: Thin Plate Spine

- title: Panorama Stitching
  demo: http://sgteja.github.io/reports/Pano.pdf
  description: In this project, two or more images were stitched together into one seamless panorama image. The estimation of homography between the pictures performed in both classical (Harris corners, RANSAC) and deep-learning methods (<a href="https://arxiv.org/pdf/1606.03798.pdf" target="_blank">HomographyNet</a>). The deep-learning approach had both supervised (HomographyNet) and <a href="https://arxiv.org/abs/1709.03966" target="_blank">unsupervised</a> methods. Although, the deep-learning techniques were able to provide satisfactory results on the synthetic data but not between two images to be stitched. Hence, I performed the stitching of images using the classical approach.
  img: Pano
  used:
    - thing: Python
    - thing: Tensor-Flow
    - thing: OpenCV
    - thing: RANSAC
    - thing: Harris corner
    - thing: Homography estimation

- title: Lane Detection
  demo: http://sgteja.github.io/reports/LaneDetection.pdf
  description: Lane Detection on a video sequence taken from a moving car. An algorithm was designed to detect lanes on the road and to estimate the road curvature to predict the turns made. The results are in these <a href="https://drive.google.com/open?id=1kwCBzWDV0Uqmww-n54ch6un3r8DlcdMQ" target="_blank">videos</a>.
  img: LaneDetection
  video: https://www.youtube.com/embed/playlist?list=PLRKLP7hn6Hr5dfSO4_SiTfHtZQOZky42Q&
  used:
    - thing: Python
    - thing: OpenCV
    - thing: Homography
    - thing: Histogram
    - thing: Sobel filter

- title: Visual Odometry
  demo: http://sgteja.github.io/reports/VisualOdometry.pdf
  description: In Visual Odometry, by utilizing successive frames of a car's movement, I generated a plot of the camera's trajectory, i.e., the path taken by the vehicle. Non-linear optimizations were performed to achieve the right pose of the camera. The input videos are from the Oxford dataset.
  img: VisualOdometry
  used: 
    - thing: Python
    - thing: OpenCV
    - thing: RANSAC
    - thing: Essential Matrix
    - thing: Triangulation
    - thing: Perspective-n-Point

- title: Traffic Sign Recognition
  demo: http://sgteja.github.io/reports/TrafficSignDetection.pdf
  description: Detection and recognition of the traffic signs are carried out in this project. In the detection stage, a pipeline was made to extract the possible candidates that contained the traffic sign. And the other part was to correctly classify the detected signals using SVM (Support Vector Machine). A video of a moving car converted into the <a href="https://drive.google.com/open?id=1gte9bEAsReCmg1wpBvpFJU3te3nLWyR-" target="_blank">output</a>, in which the signs are identified and labeled accordingly. The SVM was able to classify 62 signs provided correctly with an accuracy of 99.76% on the test data.
  img: TrafficSignDetection
  video: https://www.youtube.com/embed/KoLAG8vt2PM?
  used: 
    - thing: Python
    - thing: OpenCV
    - thing: HOG
    - thing: SVM

- title: Path Planning 
  code: https://github.com/sgteja/Path-Planning
  description: Via Path Planning, I Implemented the most popular path planning algorithms used in robotics such as A-Star, Dijkstra, and Simple Breadth-First Search. Also, the picture below is from the <a href="https://www.youtube.com/watch?v=ci5iAQYvzLE" target="_blank">implementation</a> of the A-Star algorithm for the differential drive to find the path that the turtle bot had to traverse to reach the goal position while avoiding the obstacles.
  img: PathPlanning
  video: https://www.youtube.com/embed/ci5iAQYvzLE?
  used: 
    - thing: Python
    - thing: Gazebo
    - thing: ROS 
    - thing: A-Star
    - thing: Dijkstra
# - title: Weather Widget  
#    demo: http://quiet-dusk-89245.herokuapp.com/
#   code: https://github.com/bchiang7/DemoWebApp
#   description: A simple weather app I made at HubSpot's Fall 2016 Web App Workshop utilizing Node.js, Express, and Heroku. I used the OpenWeatherMap API to get weather and forecast data, and then used the current city's coordinates to create a map background that reflected the current city using the Google Maps API.
#   img: weather
#   used:
#     - thing: OpenWeatherMap API
#     - thing: Google Maps API
#     - thing: JavaScript
#     - thing: jQuery
#     - thing: CSS
#     - thing: Node.js
#     - thing: Express
#     - thing: Heroku

# - title: Screentime 2.0
#   demo: https://play.google.com/store/apps/details?id=com.starry.management
#   description: ScreenTime 2.0 was one of <a href="https://starry.com/" target="_blank">Starry</a>'s most important consumer-facing software updates on <a href="https://starry.com/station" target="_blank">Starry Station</a>, providing new functionality for users to easily filter content, pause the internet, and even create custom rules for blocking apps like Facebook and Twitter right from their mobile phones. As a co-op, I played a large role in the implementation of this feature on Starry's cordova android app, and was responsible for building out front-end designs, linking up back-end data, as well as communicating with designers and other engineers throughout the process. <br><br> Check out the Starry App on <a href="https://play.google.com/store/apps/details?id=com.starry.management" target="_blank">Google Play</a>, and learn more about ScreenTime 2.0 on <a href="https://www.producthunt.com/tech/screentime-for-starry-station" target="_blank">Product Hunt</a> and the <a href="https://blog.starry.com/whats-new-screentime-just-got-better-for-parents/" target="_blank">Starry Blog</a>.
#   img: screentime
#   used:
#   - thing: JavaScript
#   - thing: CSS
#   - thing: Handlebars.js
#   - thing: Backbone.js
#   - thing: Marionette.js
#   - thing: Cordova

# - title: Online Resume
#   demo: http://brittanychiang.com/react-profile/
#   code: https://github.com/bchiang7/react-profile/
#   description: This is just an online version of my resume I made for fun. I was interested in learning React.js, so I found this <a href="https://medium.com/learning-new-stuff/building-your-first-react-js-app-d53b0c98dc#.1439cdewq">simple tutorial</a> and it kind of spun into this weekend project. I probably didn't need to use React at all, but hey, at least I learned a few things!
#   img: resume
#   used:
#   - thing: JavaScript
#   - thing: React.js
#   - thing: CSS

# - title: Old Personal Website
#   demo: http://brittanychiang.com/v1
#   code: https://github.com/bchiang7/website_2015/
#   description: This was my first portfolio website I built in 2014. It's a simple one-pager like this one, but relied heavily on Bootstrap. Since then, I think my web development and design skills have expanded immensely.
#   img: websitev1
#   used:
#   - thing: HTML
#   - thing: CSS
#   - thing: Bootstrap
#   - thing: JavaScript
#   - thing: jQuery

# - title: CourseSource
#   demo: http://webdevspring2016-chiangbrittany.rhcloud.com/project/client/#/login
#   code: https://github.com/bchiang7/WebDevSpring2016/tree/master/public/project
#   description: CourseSource is a web application built on the MEAN (MongoDB, Express, Angular, Node) stack for my web development class in 2015. I created this web app with the intention of providing Northeastern Students a better experience browsing the courses offered at Northeastern (which is currently a painstakingly tedious task on our current student portal).
#   img: coursesource
#   used:
#     - thing: HTML
#     - thing: CSS
#     - thing: Bootstrap
#     - thing: JavaScript
#     - thing: jQuery
#     - thing: NodeJS
#     - thing: AngularJS
#     - thing: Express
#     - thing: MongoDB

# - title: NU Women in Tech
#   demo: http://nuwit.ccs.neu.edu/
#   code: https://github.com/nuwit/website
#   description: While serving as web chair for Northeastern University Women in Technology, I did a complete overhaul of the club website. I designed and developed the current website using Jekyll as a static site generator, and was responsible for the upkeeping and maintainence of the site.
#   img: nuwit
#   used:
#     - thing: Jekyll
#     - thing: Liquid
#     - thing: Yaml
#     - thing: HTML
#     - thing: CSS
#     - thing: Bootstrap
#     - thing: jQuery

# - title: Fontipsums
#   demo: http://brittanychiang.com/fontipsums
#   code: https://github.com/bchiang7/fontipsums
#   description: As a typography nerd, I wanted a way to visually see different font combinations together. I whipped up this simple website to display some of my favorite pairings combined with some fun lorem ipsum variations I found on the web. Over the course of creating this site, I learned a lot about web fonts and best practices.
#   img: fontipsums
#   used:
#     - thing: HTML
#     - thing: SCSS

# - title: One Card For All
#   demo: http://onecardforall.org
#   description: At MullenLowe, I helped build this 2015 holiday site around an algorithm that generated a holiday greeting to each and every person on the planet. We also accounted for newcomers being added at an amazing rate. Overall, the website is a tranquil, animated experience. As new names appear, visitors can watch them fall, like snowflakes, onto a stylized world map. Users can also find their own name and see it as part of the world collective. Check out this short <a href="http://us.mullenlowe.com/work/one-card-for-all/" target="_blank">video</a> describing the project!
#   img: onecard
#   used:
#     - thing: HTML
#     - thing: SCSS
#     - thing: JavaScript
#     - thing: jQuery

# - title: JetBlue HumanKinda
#   demo: http://jetbluehumankinda.com
#   description: During my first co-op as a creative technologist at Mullen Lowe, I played a major role in the development of this Tumblr site to complement JetBlue's HumanKinda campaign and documentary. The site houses the video documentary at the top, the many graphics created by Mullen for the campaign, and an interactive quiz to determine how "HumanKinda" you are. Learn more about this project <a href="http://us.mullenlowe.com/work/humankinda/" target="_blank">here</a>!
#   img: humankinda
#   used:
#     - thing: HTML
#     - thing: CSS
#     - thing: JavaScript
#     - thing: jQuery
